<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-10-16T13:27:48-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Connor Hainje</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">Thesis</title><link href="http://localhost:4000/research/2020/09/20/thesis.html" rel="alternate" type="text/html" title="Thesis" /><published>2020-09-20T00:00:00-04:00</published><updated>2020-09-20T00:00:00-04:00</updated><id>http://localhost:4000/research/2020/09/20/thesis</id><content type="html" xml:base="http://localhost:4000/research/2020/09/20/thesis.html">&lt;p&gt;I am currently working on this. Check out my work in &lt;a href=&quot;https://github.com/cmhainje/thesis&quot;&gt;its repository&lt;/a&gt;.
Note that it’s still very early in its lifespan: check back later (or next
year!) for updates.&lt;/p&gt;

&lt;p&gt;I am working with Prof. Mariangela Lisanti of the Princeton Department of
Physics on a project to explore the impacts of different dark matter models on
the formation and evolution of the Sagittarius stream. This involves&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;knowledge of several dark matter models, including cold dark matter (CDM) and
self-interacting dark matter (SIDM),&lt;/li&gt;
  &lt;li&gt;effective usage of &lt;em&gt;N&lt;/em&gt;-body simulation tools like GADGET-2 and GIZMO,&lt;/li&gt;
  &lt;li&gt;proficiency in the usage of the Linux command-line and the SLURM job queue,&lt;/li&gt;
  &lt;li&gt;fluency in Python and data analysis methods.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="research" /><summary type="html">I am currently working on this. Check out my work in its repository. Note that it’s still very early in its lifespan: check back later (or next year!) for updates.</summary></entry><entry><title type="html">Belle II, Round II</title><link href="http://localhost:4000/research/2020/09/01/belle2.html" rel="alternate" type="text/html" title="Belle II, Round II" /><published>2020-09-01T00:00:00-04:00</published><updated>2020-09-01T00:00:00-04:00</updated><id>http://localhost:4000/research/2020/09/01/belle2</id><content type="html" xml:base="http://localhost:4000/research/2020/09/01/belle2.html">&lt;p&gt;For the second summer in a row, I’m working with Jan Strube at PNNL on the Belle
II experiment. While I’m still working primarily on the TOP subdetector, my work
is quite a bit more focused on how we can use machine learning to aid in our
analysis.&lt;/p&gt;

&lt;p&gt;So far, most of my work has gone into understanding on a deeper level the
particle identification (PID) system employed by the TOP. As Belle II continues
to run and take data, it has become increasingly evident that there are somewhat
strong discrepancies between simulation and data; namely, the data is not
performing nearly as well as expected from simulation. Understanding why this is
the case is paramount to increasing the quality of data recorded at Belle II.&lt;/p&gt;

&lt;p&gt;The TOP detector works as particle passing through emit photons (called
Cherenkov radiation) which are internally reflected through the detector until
they are absorbed and recorded by an array of photomultipliers (PMTs). This set
of photon detections (each of which consists of a time and PMT channel) are
theoretically sufficient to identify the passing particles, especially when
combined with track information that can be obtained from the particle’s
reconstructed track (information like momentum). My goal for the first part of
this internship has been to develop methods for understanding each photon’s
contribution to the TOP likelihoods for PID. This has been largely performed by
creating additional C++ and Fortran methods in the Belle II analysis software
framework, as well as by creating a new C++ data object type that can be used by
Python analysis scripts.&lt;/p&gt;

&lt;p&gt;With this work in place, it is now possible to retrieve the likelihoods on a
pixel-by-pixel basis. This allows us to understand whether patterns exist in the
contributions of photons to the likelihoods (for instance, whether early photons
are more important than late ones, or whether certain PMT channels matter more
or less). This is currently a bit of a work-in-progress, so we shall see if any
interesting results come about.&lt;/p&gt;

&lt;p&gt;The other primary part of my work is machine learning. In particular, I’m
working on machine learning for particle identification: developing a model
which, given a particle’s associated photon detections and track parameters,
classifies the particle type. This is an interesting problem because the form of
the data does not quite match that of pre-existing models. Further, it is rather
easy to show that a problem like this is solvable for a given set of track
parameters, but varying track parameters over the whole of their phase space
(which is rather large) poses the challenge of scalability. Again, this is a bit
of a work-in-progress, so check back later for potential updates.&lt;/p&gt;</content><author><name></name></author><category term="research" /><summary type="html">For the second summer in a row, I’m working with Jan Strube at PNNL on the Belle II experiment. While I’m still working primarily on the TOP subdetector, my work is quite a bit more focused on how we can use machine learning to aid in our analysis.</summary></entry><entry><title type="html">On Xword</title><link href="http://localhost:4000/projects/xword/about" rel="alternate" type="text/html" title="On Xword" /><published>2020-08-01T00:00:00-04:00</published><updated>2020-08-01T00:00:00-04:00</updated><id>http://localhost:4000/projects/xword/xword</id><content type="html" xml:base="http://localhost:4000/projects/xword/about">&lt;p&gt;Use Xword &lt;a href=&quot;https://x-word.herokuapp.com&quot;&gt;here&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;Before the COVID-19 pandemic brought about our exodus from campus, one of my
favorite pastimes was solving the Nassau Weekly’s Sunday crossword with my
friends each week. The Nass continued to post their crosswords online each week
during the remainder of our semester, but obviously it wasn’t very easy to do
them together with my friends with us spread across the United States. So I set
out to make a multiplayer crossword player web app. The result: Xword.&lt;/p&gt;

&lt;p&gt;Xword is not the most robust crossword app, but its most important feature is
that it is multiplayer. Upon connection, users may create or join a room via
room code. Once in a room, users can see the cells that other room members have
selected, and the letters placed in each cell are synced between all members of
the room. Further, one can select a clue to have the squares associated with
that clue highlighted, though this is not synced between room members, so as to
allow each member to look at a different clue if they’d like.&lt;/p&gt;

&lt;h2 id=&quot;development&quot;&gt;Development&lt;/h2&gt;

&lt;p&gt;I made Xword using React and Socket.io, and JavaScript was used exclusively for
everything not already handled by one of these libraries. React was used to
create a dynamic user interface for interacting with the crossword squares and
clues. I’d never used React before, so this project was meant to be my first
real attempt at learning React, and I think React’s strengths really lent
themselves to this type of project.&lt;/p&gt;

&lt;p&gt;I’d also never done much in the way of networking or using WebSockets. Socket.io
ended up proving rather simple and straightforward to learn for a decently
simple server implementation. Messages are passed back and forth between the
server and clients with simple &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;socket.emit()&lt;/code&gt; statements. For example, when a
player presses a key to insert a value into a square, the keypress handler emits
a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;valueUpdate&lt;/code&gt; message to the server, which relays the message back to the other
room members, whose crossword boards update correspondingly.&lt;/p&gt;</content><author><name></name></author><category term="projects" /><summary type="html">Use Xword here!</summary></entry><entry><title type="html">New project - BangNotes</title><link href="http://localhost:4000/projects/bangnotes/about" rel="alternate" type="text/html" title="New project - BangNotes" /><published>2020-07-01T00:00:00-04:00</published><updated>2020-07-01T00:00:00-04:00</updated><id>http://localhost:4000/projects/bangnotes/bangnotes</id><content type="html" xml:base="http://localhost:4000/projects/bangnotes/about">&lt;p&gt;See the code on &lt;a href=&quot;https://github.com/cmhainje/bangnotes&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;When I was making this website, something that was important to me was figuring
out how to make a space where I could type and publish notes. Often, my notes
involve the heavy usage of math. Moreso, though, my notes are always taken with
a very particular style, with certain kinds of formatting assigned to certain
situations. For example, my math notes have very specific formatting for
definitions, propositions, theorems, as opposed to the formatting I use for
proofs or even general commentary. While these types of formatting problems
aren’t particularly difficult when working with HTML, it very quickly became
very tedious to type the same div block structures repeatedly with few changes.
I wanted something flexible and lightweight that would allow me to type my notes
in a more Markdown-like style with built-in reusable components. My solution:
!BangNotes.&lt;/p&gt;

&lt;p&gt;!BangNotes is a markup language that is similar in many ways to Markdown, with
the addition of completely custom reusable component blocks called !bangs. Most
!bangs will start with a name (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;!thm&lt;/code&gt;) on their own line, followed by content
that will go inside the bang, and lastly a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;!end&lt;/code&gt; tag on its own line. Some
!bangs will take an optional argument at their declaration, like
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;!thm{Division Theorem}&lt;/code&gt;. Some !bangs also only require one line: these bangs
are formatted a bit differently, as they don’t require an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;!end&lt;/code&gt; tag. (An
example is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;!title&lt;/code&gt; bang.)&lt;/p&gt;

&lt;p&gt;One can easily define their own !bangs by creating a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.bdef&lt;/code&gt; file. !bangs are
declared by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;!name&lt;/code&gt;. If you want your bang to support an optional argument, add
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{opt}&lt;/code&gt; following the name. (Leave it out if not.) If your !bang component will
contain extended, multi-line internal content, add a space and then &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;!end&lt;/code&gt;
following the !bang declaration. Single-line !bangs are defined by the omission
of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;!end&lt;/code&gt;. The bang declaration is then followed by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:=&lt;/code&gt;. Following this, your
HTML declaration of the reusable component is placed inside curly braces. For
best results, place the opening brace on the same line as the declaration, and
the closing brace on its own line after the HTML. Inside the HTML, put
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{content}&lt;/code&gt; where you want the inner contents of the !bang block to be placed.
If your !bang takes an optional extra argument, format that in your HTML
declaration as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{opt}&lt;/code&gt;.  Note that the entire line containing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{opt}&lt;/code&gt; will be
omitted if the !bang block is called but an optional argument isn’t given.&lt;/p&gt;

&lt;p&gt;Here is a sample !bang definition.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;!thm{opt} !end := {
  &amp;lt;div class=&quot;block&quot;&amp;gt;
    &amp;lt;div class=&quot;block-name&quot;&amp;gt;
      theorem
    &amp;lt;/div&amp;gt;
    &amp;lt;div class=&quot;block-content&quot;&amp;gt;
      &amp;lt;h3&amp;gt;{opt}&amp;lt;/h3&amp;gt;
      {content}
    &amp;lt;/div&amp;gt;
  &amp;lt;/div&amp;gt;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now, with this !bang defined in our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.bdef&lt;/code&gt; file, we can use it in a !bangNote.
For example,&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;!thm{Division Theorem}
For all $x \in \mathbb{Z}$, there exists a unique $q, r \in
\mathbb{Z}$ with $0 \leq r &amp;lt; n$ so that
\[ x = n \cdot q + r. \]
In this case, we call $x$ the &quot;dividend&quot;, $n$ the &quot;divisor&quot;,
$q$ the &quot;quotient&quot;, and $r$ the &quot;remainder&quot;.
!end
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will then be compiled to the following HTML.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;div class=&quot;block&quot;&amp;gt;
  &amp;lt;div class=&quot;block-name&quot;&amp;gt;
    theorem
  &amp;lt;/div&amp;gt;
  &amp;lt;div class=&quot;block-content&quot;&amp;gt;
    &amp;lt;h3&amp;gt;Division Theorem&amp;lt;/h3&amp;gt;
    &amp;lt;p&amp;gt;
      For all \(x \in \mathbb{Z}\), there exists a unique
      \(q, r \in \mathbb{Z}\) with \(0 \leq r &amp;lt; n\) so that
      \[ x = n \cdot q + r. \]
      In this case, we call \(x\) the &quot;dividend&quot;, \(n\) the
      &quot;divisor&quot;, \(q\) the &quot;quotient&quot;, and \(r\) the
      &quot;remainder&quot;.
    &amp;lt;/p&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In practice, I’ve added an additional block at the end of the compiler that adds
typical HTML default things like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;html&amp;gt;&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;head&amp;gt;&lt;/code&gt;, etc., as well as references
to my own pre-defined CSS files, MathJax scrips, etc. This would all be very
easily customized to meet the needs of anyone using the compiler.&lt;/p&gt;</content><author><name></name></author><category term="projects" /><summary type="html">See the code on GitHub.</summary></entry><entry><title type="html">Junior Paper - SPIDER</title><link href="http://localhost:4000/research/2020/05/30/spring-jp.html" rel="alternate" type="text/html" title="Junior Paper - SPIDER" /><published>2020-05-30T00:00:00-04:00</published><updated>2020-05-30T00:00:00-04:00</updated><id>http://localhost:4000/research/2020/05/30/spring-jp</id><content type="html" xml:base="http://localhost:4000/research/2020/05/30/spring-jp.html">&lt;p&gt;&lt;a href=&quot;/assets/resources/spring-jp.pdf&quot;&gt;See the paper.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My second junior paper, performed under the advisory of Prof. Bill Jones. For
this research, I worked as a member of the &lt;a href=&quot;https://spider.princeton.edu&quot;&gt;SPIDER experiment&lt;/a&gt;.
SPIDER is an experiment designed to measure the polarized CMB with unprecedented
resolution.  The SPIDER apparatus is a balloon-borne polarimeter which underwent
data-taking flights back in 2015.  My work was largely concerned with analyzing
the data polarized CMB maps taken during these flights. In particular, I was
tasked with developing a method for quantifying the degree to which signals from
galactic dust remained present in the SPIDER maps after cleaning them.&lt;/p&gt;

&lt;p&gt;The presence of galactic dust in maps of the polarized CMB is a problem that
plagues most experiments like SPIDER, so it is necessary to develop
sophisticated methods to remove these signals from CMB maps. Galactic dust
orients itself with local magnetic field structures, which causes its thermal
radiation and starlight re-radiation to be polarized in preferred directions.
This radiation tends to be at similar wavelengths to CMB radiation, so we need
to clean CMB maps of this radiation in order to be sure that any patterns we see
are definitively not from galactic dust.&lt;/p&gt;

&lt;p&gt;Researchers Clark and Hensley recently (2019) published a paper wherein they
describe correlations between galactic HI structures and galactic dust,
presenting a new method by which one can probe (and quantify) the degree to
which a CMB map contains dusty signals. Most of my research involved trying to
reproduce their work in which they calculated two correlation metrics between HI
maps and the Planck 353 GHz map (a map which is known to be dominated by dusty
signals, and thus a good approximation of a plain map of galactic dust).&lt;/p&gt;

&lt;p&gt;The end goal of this research was to complete the reproduction of Clark and
Hensley’s correlation calculations, and then to use the correlation
calculating-pipeline to calculate the same correlations between the cleaned
SPIDER maps and galactic HI maps as an independent measure of the presence of
dusty signals in the cleaned maps. Unfortunately, I was never able to fully
reproduce Clark and Hensley’s calculations, in large part simply because we ran
out of time.&lt;/p&gt;

&lt;p&gt;My work still provided me with a good amount of new knowledge, though, and this
is all summarized in the paper. Further, my inability to reproduce the C&amp;amp;H
result is important in its own right: if other researchers similarly try and
fail to reproduce the plot, then there is potentially an error in Clark and
Hensley’s work that needs to be corrected.&lt;/p&gt;</content><author><name></name></author><category term="research" /><summary type="html">See the paper.</summary></entry><entry><title type="html">Junior Paper - Gravitational Wave Review</title><link href="http://localhost:4000/research/2019/12/31/fall-jp.html" rel="alternate" type="text/html" title="Junior Paper - Gravitational Wave Review" /><published>2019-12-31T00:00:00-05:00</published><updated>2019-12-31T00:00:00-05:00</updated><id>http://localhost:4000/research/2019/12/31/fall-jp</id><content type="html" xml:base="http://localhost:4000/research/2019/12/31/fall-jp.html">&lt;p&gt;&lt;a href=&quot;/assets/resources/fall-jp.pdf&quot;&gt;See the paper.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the physics department at Princeton, concentrators are required to do an
independent research project each semester of their junior year. This is the
project I completed for the fall semester, under the advisory of Prof. Herman
Verlinde.&lt;/p&gt;

&lt;p&gt;The project was a literature review in which I reviewed the theory relevant to
the gravitational waveforms produced during black hole mergers. The paper starts
with a brief overview of the general relativity necessary to describe black
holes and gravitational waves. It then merges the two to show the waves produced
by black hole mergers, and culminates in a discussion of the waveforms of the
ringdown phase specifically. This involves a discussion of the theory of
quasinormal modes, the importance of overtones in waveform analysis, and methods
for parameter recovery.&lt;/p&gt;

&lt;p&gt;This project is chiefly important because it serves as my first foray into
astrophysics. Over the past few semesters, I’ve become increasingly interested
in diversifying my research a bit and beginning to do something on a “larger”
scale, given that most of my background has been with nuclear and particle
physics. This project, then, represented the beginning of an endeavor to do just
that, and I found the whole experience greatly enjoyable. I really liked what
general relativity I learned, as well as the physics I picked up to describe
black holes and gravitational waves. On the whole, it was a fun project, and I’d
love to do more in the same vein in the future.&lt;/p&gt;</content><author><name></name></author><category term="research" /><summary type="html">See the paper.</summary></entry><entry><title type="html">Belle II at PNNL</title><link href="http://localhost:4000/research/2019/09/15/belle2.html" rel="alternate" type="text/html" title="Belle II at PNNL" /><published>2019-09-15T00:00:00-04:00</published><updated>2019-09-15T00:00:00-04:00</updated><id>http://localhost:4000/research/2019/09/15/belle2</id><content type="html" xml:base="http://localhost:4000/research/2019/09/15/belle2.html">&lt;p&gt;In the summer of 2019, I worked at Pacific Northwest National Lab in Richland,
WA as a part of the U.S. D.O.E.’s &lt;a href=&quot;https://science.osti.gov/wdts/suli/&quot;&gt;Science Undergraduate Laboratory Internships
(SULI)&lt;/a&gt; program. I worked with Dr. Jan Strube as a member of the
Belle II experiment. Belle II is an \(e^+ e^-\) collider experiment. My work was
primarily involved with a particular subdetector of the full Belle II detector
system called the Time-of-Propagation, or TOP, detector. In particular, I
performed a deep analysis of the TOP detector to try to uncover regions of
better or worse performance. Then, I built a novel framework for Monte
Carlo-based TOP likelihood calculation.&lt;/p&gt;

&lt;p&gt;The TOP detector is at the core of the Belle II particle identification (PID)
system. The way it works is by harnessing the phenomenon of Cherenkov radiation.
In general, when a particle is traveling through matter at a speed faster than
the local speed of light in the matter, it will emit photons along a cone around
the particle. In a sense, it’s the optical analogue of a “sonic boom.” As such,
the TOP detector consists primarily of a vary large quartz bar, through which
high energy particles will pass after collision events. As they move through the
bar, they produce photons in the quartz. These photons are internally reflected
throughout the quartz bar until they reach an array of photomultipliers (PMTs)
at one end of the TOP detector, where the photons are detected. From this
readout, we can in theory reconstruct the angle between the particle’s path
through the TOP detector and the emitted Cherenkov photons. This angle is
characteristic for each kind of particle, and thus allows us to identify the
particle that has just been detected.&lt;/p&gt;

&lt;p&gt;The TOP detector has many weird quirks, and most of my summer was spent trying
to uncover and describe some of these. One of the primary things I explored was
whether there exists any spatial dependence of the TOP detector’s likelihood
performance. This primarily consisted of using Geant4 to simulate millions of
collision events in the Belle II detector. I then binned all events based on
their entry positions into the TOP detector and analyzed various quantities,
such as pion-kaon separation power, as a function of bar entry coordinates. We
found some interesting phenomena.&lt;/p&gt;

&lt;p&gt;For example, there is a region about two-thirds of the way along the bar, away
from the PMT array, where performance is surprisingly boosted. This region, we
found, corresponds to a region where track geometry combines with the geometry
of the quartz bar to preserve far more photons. Namely, the majority of photons
produced by an incident particle do not make it to be detected by the PMT array,
but in this region, the angles are just right such that a higher number of
photons are preserved and detected.&lt;/p&gt;

&lt;p&gt;The latter half of my summer was spent building a computational framework for
Monte Carlo-based likelihood calculations. The idea here was to replace the
analytic TOP likelihood calculation system with a system backed entirely by
Geant4 simulation data. Why? Preliminary data runs showed that the analytic
likelihood system in the TOP was underperforming in real data compared to
simulation. Further, the analytic likelihood distributions often did not match
the MC distributions. As such, we desired to see whether an MC-backed likelihood
calculation, which effectively amounts to a very, very large, multi-dimensional
histogram, could outperform the analytic likelihoods.&lt;/p&gt;

&lt;p&gt;This project required the development of an optimized computational framework,
as the amount of data required to cover the phase space of particle tracks is
extremely large. Optimization required the development of basic parallelization
and multiprocessing techniques, as well as the development of a smart, optimal
storage system for the data.&lt;/p&gt;

&lt;p&gt;In the end, we were not able to beat the analytic likelihood system’s
performance on simulation data, but we were able to come somewhat close.
However, the real test of this system would be measuring its performance on
data, but the level of data production was still quite low by the time I was
leaving Richland.&lt;/p&gt;

&lt;p&gt;This project resulted in the publication of a Belle II Internal Technical Note.&lt;/p&gt;</content><author><name></name></author><category term="research" /><summary type="html">In the summer of 2019, I worked at Pacific Northwest National Lab in Richland, WA as a part of the U.S. D.O.E.’s Science Undergraduate Laboratory Internships (SULI) program. I worked with Dr. Jan Strube as a member of the Belle II experiment. Belle II is an \(e^+ e^-\) collider experiment. My work was primarily involved with a particular subdetector of the full Belle II detector system called the Time-of-Propagation, or TOP, detector. In particular, I performed a deep analysis of the TOP detector to try to uncover regions of better or worse performance. Then, I built a novel framework for Monte Carlo-based TOP likelihood calculation.</summary></entry><entry><title type="html">Introducing Pomodoro</title><link href="http://localhost:4000/projects/pomodoro/about" rel="alternate" type="text/html" title="Introducing Pomodoro" /><published>2019-07-01T00:00:00-04:00</published><updated>2019-07-01T00:00:00-04:00</updated><id>http://localhost:4000/projects/pomodoro/pomodoro</id><content type="html" xml:base="http://localhost:4000/projects/pomodoro/about">&lt;p&gt;Here is the project: &lt;a href=&quot;/pomodoro/index.html&quot;&gt;link&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Pomodoro is a simple Pomodoro timer that I built to help me manage my time more
effectively at &lt;a href=&quot;/research//2019/09/15/belle2.html&quot;&gt;my internship&lt;/a&gt; this summer.
It is a productivity method designed to help minimize mental distractions due to
burnout by building many short breaks into the workday. Each of these breaks
helps the mind to reset itself. Further, each work period is only 25 minutes
long, so even when you’re tired, it’s relatively easy to push yourself to work
toward the next break.&lt;/p&gt;

&lt;p&gt;I found this method very helpful, and even saw that my productivity improved.
While on a typical day I would start feeling really burnt out around 3:00pm, I
found that I would be able to work all the way until leaving without feeling
exhausted (and with less eye strain!).&lt;/p&gt;</content><author><name></name></author><category term="projects" /><summary type="html">Here is the project: link.</summary></entry><entry><title type="html">Purdue MFRL</title><link href="http://localhost:4000/research/2017/06/01/mfrl.html" rel="alternate" type="text/html" title="Purdue MFRL" /><published>2017-06-01T00:00:00-04:00</published><updated>2017-06-01T00:00:00-04:00</updated><id>http://localhost:4000/research/2017/06/01/mfrl</id><content type="html" xml:base="http://localhost:4000/research/2017/06/01/mfrl.html">&lt;p&gt;In high school, I worked as a research assistant at the Purdue University
Metastable Fluid Research Laboratory (MFRL), a lab that works primarily on
nuclear detection physics. The laboratory specializes in neutron detectors
called TMFDs, or Tensioned Metastable Fluid Detectors. These detectors work by
putting fluids into a metastable state, in which interaction with a neutron with
enough energy would directly cause the liquid to change to gas. My work was
primarily with helping to build a spectroscopic model for these detectors, from
first physics principles as best as possible. The physics surrounding tensioned
fluids is not super well understood, so much of the work required building our
model from the ground up. In pursuit of this aim, I&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Helped to develop a model for spectroscopy methods&lt;/li&gt;
  &lt;li&gt;Wrote MCNP decks for nuclear simulation to refine our model&lt;/li&gt;
  &lt;li&gt;Designed and constructed an experimental apparatus, by&lt;/li&gt;
  &lt;li&gt;Designing and constructing constant-temperature chamber&lt;/li&gt;
  &lt;li&gt;Programming an Arduino microcontroller for temperature regulation&lt;/li&gt;
  &lt;li&gt;Performed precise scientific experimentation&lt;/li&gt;
  &lt;li&gt;Wrote analysis scripts to test our model with MCNP output as well as
experimental data&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="research" /><summary type="html">In high school, I worked as a research assistant at the Purdue University Metastable Fluid Research Laboratory (MFRL), a lab that works primarily on nuclear detection physics. The laboratory specializes in neutron detectors called TMFDs, or Tensioned Metastable Fluid Detectors. These detectors work by putting fluids into a metastable state, in which interaction with a neutron with enough energy would directly cause the liquid to change to gas. My work was primarily with helping to build a spectroscopic model for these detectors, from first physics principles as best as possible. The physics surrounding tensioned fluids is not super well understood, so much of the work required building our model from the ground up. In pursuit of this aim, I</summary></entry></feed>